#!/usr/bin/env python3
"""
Callback Ð´Ð»Ñ Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ð¸ ÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ñ LiteLLM Router.
"""

from __future__ import annotations

import logging
from typing import Any, Dict, List

logger = logging.getLogger(__name__)


def update_models_in_router(models: List[Dict[str, Any]]) -> None:
    """
    ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð² LiteLLM Router Ñ‡ÐµÑ€ÐµÐ· upsert_deployment.
    
    Ð¢ÐµÐ¿ÐµÑ€ÑŒ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ Ð² Ñ‚Ð¾Ð¼ Ð¶Ðµ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐµ, Ñ‡Ñ‚Ð¾ Ð¸ LiteLLM ÑÐµÑ€Ð²ÐµÑ€,
    Ð¿Ð¾ÑÑ‚Ð¾Ð¼Ñƒ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ ÑÑ€Ð°Ð·Ñƒ Ð²Ð¸Ð´Ð½Ñ‹ Ð² /v1/models.
    """
    try:
        import litellm.proxy.proxy_server as proxy_server
        from litellm.types.router import Deployment, LiteLLM_Params, ModelInfo
        
        logger.info(f"âš¡ Ð—Ð°Ð¿ÑƒÑ‰ÐµÐ½ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ {len(models)} Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð² LiteLLM...")

        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ Router ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚
        if not hasattr(proxy_server, "llm_router") or proxy_server.llm_router is None:
            logger.warning("âš ï¸ Router ÐµÑ‰Ñ‘ Ð½Ðµ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½, Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ")
            return
        
        logger.info(f"ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ {len(models)} Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð² Router...")
        
        # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ upsert_deployment Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸
        added_count = 0
        updated_count = 0
        
        for model in models:
            try:
                model_name = model.get("model_name")
                litellm_params_dict = model.get("litellm_params", {})
                
                if not model_name or not litellm_params_dict:
                    logger.warning(f"âš ï¸ ÐŸÑ€Ð¾Ð¿ÑƒÑÐº Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ñ Ð½ÐµÐ¿Ð¾Ð»Ð½Ñ‹Ð¼Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸: {model}")
                    continue
                
                # Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ LiteLLM_Params
                litellm_params = LiteLLM_Params(
                    model=litellm_params_dict.get("model"),
                    api_base=litellm_params_dict.get("api_base"),
                    api_key=litellm_params_dict.get("api_key", "none"),
                    timeout=litellm_params_dict.get("timeout"),
                )
                
                # Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ Deployment
                deployment = Deployment(
                    model_name=model_name,
                    litellm_params=litellm_params,
                    model_info=ModelInfo()
                )
                
                # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼/Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð² Router
                result = proxy_server.llm_router.upsert_deployment(deployment)
                
                if result is not None:
                    added_count += 1
                    logger.debug(f"  âœ“ Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð°: {model_name}")
                else:
                    updated_count += 1
                    logger.debug(f"  â†» ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð°: {model_name}")
                    
            except Exception as model_exc:
                logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸ {model.get('model_name')}: {model_exc}")
                continue
        
        logger.info(f"âœ… Router Ð¾Ð±Ð½Ð¾Ð²Ð»Ñ‘Ð½: Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¾ {added_count}, Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾ {updated_count} Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹")
        
        # Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÐ¼ Ñ‚ÐµÐºÑƒÑ‰Ð¸Ð¹ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹
        current_models = proxy_server.llm_router.get_model_names()
        logger.info(f"ðŸ“‹ Ð¢ÐµÐºÑƒÑ‰Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð² Router ({len(current_models)}):")
        for model_name in current_models:
            logger.info(f"  - {model_name}")

    except Exception as exc:
        logger.error(f"ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ: {exc}", exc_info=True)


def get_update_callback() -> callable:
    return update_models_in_router
